Package: negControlsSimulation
Type: Package
Title: Simulation Study of Negative Controls Violating the Null-Assumption
Version: 0.1.0
Author: Erica A Voss
Maintainer: The package maintainer <Erica A Voss>
Description: The simulation study provided valuable insights into the influence of non-null negative controls on the derived null distribution. We systematically varied several key parameters, including the number of non-null negative controls, the true effect size of the outcome under investigation, and the systematic error inherent in the methodology. Since the outcome of interest is known in the simulation, we could assess how non-null negative controls affected both the coverage (i.e., the frequency with which the CI contains the true effect size of the outcome) and precision (i.e., the width of the CI) of our estimates. We conducted this assessment for each parameter configuration both before and after calibration. <br> Within each simulation, we generated fifty negative controls. These controls comprised a mix of non-null and null negative controls, with variations ranging from 0 non-null and 50 null negative controls (0-50), 1-49, 3-47, and 9-41. In cases where the set of negative controls included non-null negative controls, we simulated three effect sizes: 1.5, 2.0, and 4.0. Random error was introduced, sampled within the range of 0.01 to 0.5 when generating the negative control set. This simulation allows the standard error to be known with certainty and this is what was used to calibrate in empirical calibration. <br> To simulate outcomes, we employed effect sizes of 1.0, 1.5, 2.0, and 4.0. These true effect sizes were further subjected to random error, with values of 0.1, 0.2, 0.3, and 0.6. <br> Our simulations considered studies with varying levels of residual systematic error, often arising from uncontrolled confounding. A systematic error with a mean of 0.0 and a standard deviation (SD) of 0.0 signified the implementation of a perfect method. Slightly less ideal conditions were represented by a systematic error with a mean of 0.0 and an SD of 0.2. To mimic a poor method, a systematic error with a mean of 0.2 and an SD of 0.2 was applied. <br> In total, we conducted 600 unique scenarios, as summarized in Table 1, each of which was run 1,000 times. For each replication of the simulation, we calculated the average frequency with which the CI included the true relative risk of the simulated outcome (a value ranging from 0 to 1, with an expected coverage of 95%) and the geometric mean of the precision of the CI (with higher values indicating narrower intervals).
License: Apache License 2.0
Encoding: UTF-8
LazyData: true
